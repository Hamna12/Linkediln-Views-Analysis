{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linkediln Analytics With Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick OverView:\n",
    "## ----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkedIn doesn't offer content analytics other than for each individual post separately. \n",
    "#### What if we want to see performance of our posts (likes, views, comments) over the past month? \n",
    "#### I wrote a program in Python that would visualize whether the number of views on my post went up or down over the past days, and here is what I got:\n",
    "### -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First I Install Selenium...\n",
    "# What Actually a Selenium is???\n",
    "### Selenium is a portable framework for testing web applications by multiple programming languages, including Python.\n",
    "### It is a Python library that contains methods that allow to navigate through Google Chrome and other browsers (Here I used Chrome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (4.1.5)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from selenium) (0.20.0)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: async-generator>=1.10 in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.10)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.2.2)\n",
      "Requirement already satisfied: cffi>=1.14; os_name == \"nt\" and implementation_name != \"pypy\" in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.3)\n",
      "Requirement already satisfied: cryptography>=1.3.4; extra == \"secure\" in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.1)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14; extra == \"secure\" in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (19.1.0)\n",
      "Requirement already satisfied: certifi; extra == \"secure\" in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2020.6.20)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6; extra == \"socks\" in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from cffi>=1.14; os_name == \"nt\" and implementation_name != \"pypy\"->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: six>=1.4.1 in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from cryptography>=1.3.4; extra == \"secure\"->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then I import Packages for Managing Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages for managing web scrapping\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\silicon computers\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#request user input for LinkedIn username and password:\n",
    "print(\"Please enter the exact LinkedIn username you use to login (email/phone?):\")\n",
    "username_string = str(input()) \n",
    "print()\n",
    "print(\"Please enter the exact LinkedIn password:\")\n",
    "password_string = str(input())\n",
    "print()\n",
    "print(\"Please enter your usernmae exactly how it appears in your profile link (after '/in') :\")\n",
    "link_username = str(input())\n",
    "print()\n",
    "print(\"Please enter the number of the last posts you want to analyse:\")\n",
    "number_of_posts = int(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(\"chromedrivers.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the LinkedIn login page and login under a specified account:\n",
    "browser.get('https://www.linkedin.com/login')\n",
    "#enter the specified information to login to LinkedIn:\n",
    "elementID = browser.find_element_by_id('username')\n",
    "elementID.send_keys(username_string)\n",
    "elementID = browser.find_element_by_id('password')\n",
    "elementID.send_keys(password_string)\n",
    "elementID.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the recent post activity page of the LinkedIn user you specified:\n",
    "recent_activity_link = \"https://www.linkedin.com/in/\" + link_username + \"-3456bb1b8/recent-activity/shares/\"\n",
    "browser.get(recent_activity_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __________________STEP_2:_SCRAP_POST_STATS_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate number of scrolls depending on the input\n",
    "number_of_scrolls = -(-number_of_posts // 5)  # 5 is LinkedIn's number of posts per scroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need a loop because we have a particular number of scrolls...\n",
    "views = []\n",
    "\n",
    "SCROLL_PAUSE_TIME = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scroll height\n",
    "last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "for scroll in range(number_of_scrolls) : \n",
    "    # Scroll down to bottom\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query the contents (returns service reponse object with web contents, url headers, status and other):\n",
    "src = browser.page_source\n",
    "#beautiful soup instance:\n",
    "soup = BeautifulSoup(src, features=\"lxml\")   #lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find LIKES on LinkedIn\n",
    "#### look for \"span\" tags that have the specific following attribute (click 'inspect' on the L-in page)\n",
    "#### need to convert the list of bs4 tags into strings and then extract \n",
    "#### find these specific tags (\"<stuff>\") in the soup contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_bs4tags = soup.find_all(\"span\", attrs = {\"class\" : \"v-align-middle social-details-social-counts__reactions-count\"})\n",
    "#converts a list of 1 string to int, appends to likes list\n",
    "for tag in likes_bs4tags:\n",
    "    strtag = str(tag)\n",
    "    #the first argument in findall (below) is a regular expression (accounts for commas in the number)\n",
    "    list_of_matches = re.findall('[,0-9]+',strtag)\n",
    "    #converts the last element (string) in the list to int, appends to likes list\n",
    "    last_string = list_of_matches.pop()\n",
    "    without_comma = last_string.replace(',','')\n",
    "    likes_int = int(without_comma)\n",
    "    likes.append(likes_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find VIEWS on LinkedIn\n",
    "#same concept here\n",
    "views_bs4tags = soup.find_all(\"span\", attrs = {\"class\" : \"icon-and-text-container t-14 t-black--light t-normal\"})\n",
    "for tag in views_bs4tags:\n",
    "    strtag = str(tag)\n",
    "    list_of_matches = re.findall('[,0-9]+',strtag)\n",
    "    last_string = list_of_matches.pop()\n",
    "    without_comma = last_string.replace(',','')\n",
    "    views_int = int(without_comma)\n",
    "    views.append(views_int)  \n",
    "    \n",
    "print(views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ______________STEP_3:_DATA_VISUALISATION______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the lists\n",
    "views.reverse()\n",
    "\n",
    "# Convert lists into pandas DataFrames\n",
    "views_df = pd.DataFrame(views, columns =['Views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the outliers\n",
    "#   remove data points if further than 3 standard deviations away...\n",
    "views_df_no_outliers = views_df[np.abs(views_df-views_df.median()) <= (3*views_df.std())]\n",
    "\n",
    "#   replace NaN values (deleted outliers) with the median values\n",
    "views_df_no_outliers['Views'].fillna((views_df_no_outliers['Views'].median()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('**************************')\n",
    "print('********* VIEWS **********')\n",
    "print('**************************')\n",
    "coefficients_views, residuals_views, _, _, _ = np.polyfit(range(len(views_df_no_outliers)),views_df_no_outliers,1,full=True)\n",
    "mse_views = (residuals_views[0])/(len(views_df_no_outliers))\n",
    "nrmse_views = (np.sqrt(mse_views))/(views_df_no_outliers.max() - views_df_no_outliers.min())\n",
    "slope_views = coefficients_views[0]\n",
    "print('Slope: ' + str(slope_views))\n",
    "print('NRMSE Error: ' + str(nrmse_views))\n",
    "plt.plot(views_df_no_outliers)\n",
    "plt.plot([slope_views*x + coefficients_views[1] for x in range(len(views_df_no_outliers))])\n",
    "plt.title('LinkedIn Post Views for ' + link_username)\n",
    "plt.xlabel('Posts')\n",
    "plt.ylabel('Views')\n",
    "plt.savefig(link_username + '-linkedin-views-last-' + str(number_of_posts) + '-posts-GRAPH.png', dpi=600)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes as CSV files \n",
    "views_df_no_outliers.to_csv(link_username + '-linkedin-views-last-' + str(number_of_posts) + '-posts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THANK-YOU!\n",
    "# HAPPY CODING:)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
